{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembuatan Model machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libry yang di gunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = pd.read_csv('../Projeck/data/hasil_pelabelan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_casefoldingText</th>\n",
       "      <th>text_slangwords</th>\n",
       "      <th>text_tokenizingText</th>\n",
       "      <th>text_stopword</th>\n",
       "      <th>text_akhir</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya bener2 ngga suka sama yang namanya Kurir ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Saya bener ngga suka sama yang namanya Kurir R...</td>\n",
       "      <td>saya bener ngga suka sama yang namanya kurir r...</td>\n",
       "      <td>saya benar tidak suka sama yang namanya kurir ...</td>\n",
       "      <td>['saya', 'benar', 'tidak', 'suka', 'sama', 'ya...</td>\n",
       "      <td>['suka', 'namanya', 'kurir', 'rekomendasi', 'm...</td>\n",
       "      <td>suka namanya kurir rekomendasi molor kurir upd...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>menurut saya sih sejauh ini cukup praktis untu...</td>\n",
       "      <td>4</td>\n",
       "      <td>menurut saya sih sejauh ini cukup praktis untu...</td>\n",
       "      <td>menurut saya sih sejauh ini cukup praktis untu...</td>\n",
       "      <td>menurut saya sih sejauh ini cukup praktis untu...</td>\n",
       "      <td>['menurut', 'saya', 'sih', 'sejauh', 'ini', 'c...</td>\n",
       "      <td>['praktis', 'berbelanja', 'online', 'produk', ...</td>\n",
       "      <td>praktis berbelanja online produk tersedia harg...</td>\n",
       "      <td>32</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tokopedia makin hari semakin tidak nyaman bagi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tokopedia makin hari semakin tidak nyaman bagi...</td>\n",
       "      <td>tokopedia makin hari semakin tidak nyaman bagi...</td>\n",
       "      <td>tokopedia makin hari semakin tidak nyaman bagi...</td>\n",
       "      <td>['tokopedia', 'makin', 'hari', 'semakin', 'tid...</td>\n",
       "      <td>['tokopedia', 'nyaman', 'penjual', 'cs', 'ai',...</td>\n",
       "      <td>tokopedia nyaman penjual cs ai automatic reply...</td>\n",
       "      <td>14</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gratis ongkirnya jadi ga bisa dipake, di produ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gratis ongkirnya jadi ga bisa dipake di produk...</td>\n",
       "      <td>gratis ongkirnya jadi ga bisa dipake di produk...</td>\n",
       "      <td>gratis ongkirnya jadi tidak bisa dipakai di pr...</td>\n",
       "      <td>['gratis', 'ongkirnya', 'jadi', 'tidak', 'bisa...</td>\n",
       "      <td>['gratis', 'ongkirnya', 'dipakai', 'produk', '...</td>\n",
       "      <td>gratis ongkirnya dipakai produk label gratis o...</td>\n",
       "      <td>16</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baru pakai aplikasi dapat potongan harga, pesa...</td>\n",
       "      <td>1</td>\n",
       "      <td>Baru pakai aplikasi dapat potongan harga pesan...</td>\n",
       "      <td>baru pakai aplikasi dapat potongan harga pesan...</td>\n",
       "      <td>baru pakai aplikasi dapat potongan harga pesan...</td>\n",
       "      <td>['baru', 'pakai', 'aplikasi', 'dapat', 'potong...</td>\n",
       "      <td>['pakai', 'aplikasi', 'potongan', 'harga', 'pe...</td>\n",
       "      <td>pakai aplikasi potongan harga pesanan dibatalk...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  score  \\\n",
       "0  Saya bener2 ngga suka sama yang namanya Kurir ...      2   \n",
       "1  menurut saya sih sejauh ini cukup praktis untu...      4   \n",
       "2  Tokopedia makin hari semakin tidak nyaman bagi...      1   \n",
       "3  Gratis ongkirnya jadi ga bisa dipake, di produ...      1   \n",
       "4  Baru pakai aplikasi dapat potongan harga, pesa...      1   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  Saya bener ngga suka sama yang namanya Kurir R...   \n",
       "1  menurut saya sih sejauh ini cukup praktis untu...   \n",
       "2  Tokopedia makin hari semakin tidak nyaman bagi...   \n",
       "3  Gratis ongkirnya jadi ga bisa dipake di produk...   \n",
       "4  Baru pakai aplikasi dapat potongan harga pesan...   \n",
       "\n",
       "                                text_casefoldingText  \\\n",
       "0  saya bener ngga suka sama yang namanya kurir r...   \n",
       "1  menurut saya sih sejauh ini cukup praktis untu...   \n",
       "2  tokopedia makin hari semakin tidak nyaman bagi...   \n",
       "3  gratis ongkirnya jadi ga bisa dipake di produk...   \n",
       "4  baru pakai aplikasi dapat potongan harga pesan...   \n",
       "\n",
       "                                     text_slangwords  \\\n",
       "0  saya benar tidak suka sama yang namanya kurir ...   \n",
       "1  menurut saya sih sejauh ini cukup praktis untu...   \n",
       "2  tokopedia makin hari semakin tidak nyaman bagi...   \n",
       "3  gratis ongkirnya jadi tidak bisa dipakai di pr...   \n",
       "4  baru pakai aplikasi dapat potongan harga pesan...   \n",
       "\n",
       "                                 text_tokenizingText  \\\n",
       "0  ['saya', 'benar', 'tidak', 'suka', 'sama', 'ya...   \n",
       "1  ['menurut', 'saya', 'sih', 'sejauh', 'ini', 'c...   \n",
       "2  ['tokopedia', 'makin', 'hari', 'semakin', 'tid...   \n",
       "3  ['gratis', 'ongkirnya', 'jadi', 'tidak', 'bisa...   \n",
       "4  ['baru', 'pakai', 'aplikasi', 'dapat', 'potong...   \n",
       "\n",
       "                                       text_stopword  \\\n",
       "0  ['suka', 'namanya', 'kurir', 'rekomendasi', 'm...   \n",
       "1  ['praktis', 'berbelanja', 'online', 'produk', ...   \n",
       "2  ['tokopedia', 'nyaman', 'penjual', 'cs', 'ai',...   \n",
       "3  ['gratis', 'ongkirnya', 'dipakai', 'produk', '...   \n",
       "4  ['pakai', 'aplikasi', 'potongan', 'harga', 'pe...   \n",
       "\n",
       "                                          text_akhir  polarity_score  polarity  \n",
       "0  suka namanya kurir rekomendasi molor kurir upd...               5  positive  \n",
       "1  praktis berbelanja online produk tersedia harg...              32  positive  \n",
       "2  tokopedia nyaman penjual cs ai automatic reply...              14  positive  \n",
       "3  gratis ongkirnya dipakai produk label gratis o...              16  positive  \n",
       "4  pakai aplikasi potongan harga pesanan dibatalk...               0   neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Slpiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus NaN dari X dan y secara bersamaan\n",
    "data_model = data_model.dropna(subset=['text_akhir', 'polarity'])\n",
    "\n",
    "# Pisahkan kembali fitur dan label\n",
    "X = data_model['text_akhir']\n",
    "y = data_model['polarity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstraksi fitur dengan TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000, min_df=17, max_df=0.8 )\n",
    "X_tfidf = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi hasil ekstraksi fitur menjadi dataframe\n",
    "model_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagi data menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)  # Langsung encode y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adik</th>\n",
       "      <th>adil</th>\n",
       "      <th>adm</th>\n",
       "      <th>admin</th>\n",
       "      <th>administrasi</th>\n",
       "      <th>adminnya</th>\n",
       "      <th>ads</th>\n",
       "      <th>aduh</th>\n",
       "      <th>affiliate</th>\n",
       "      <th>aga</th>\n",
       "      <th>...</th>\n",
       "      <th>wifi</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>wishlist</th>\n",
       "      <th>wktu</th>\n",
       "      <th>wkwk</th>\n",
       "      <th>wkwkwk</th>\n",
       "      <th>wkwkwkwk</th>\n",
       "      <th>worth</th>\n",
       "      <th>wow</th>\n",
       "      <th>xiaomi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 2827 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adik  adil  adm  admin  administrasi  adminnya  ads  aduh  affiliate  aga  \\\n",
       "0   0.0   0.0  0.0    0.0           0.0       0.0  0.0   0.0        0.0  0.0   \n",
       "1   0.0   0.0  0.0    0.0           0.0       0.0  0.0   0.0        0.0  0.0   \n",
       "\n",
       "   ...  wifi  wilayah  wishlist  wktu  wkwk  wkwkwk  wkwkwkwk  worth  wow  \\\n",
       "0  ...   0.0      0.0       0.0   0.0   0.0     0.0       0.0    0.0  0.0   \n",
       "1  ...   0.0      0.0       0.0   0.0   0.0     0.0       0.0    0.0  0.0   \n",
       "\n",
       "   xiaomi  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "\n",
       "[2 rows x 2827 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Model Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat model dengan algoritma Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat objek model Naive Bayes (Bernoulli Naive Bayes)\n",
    "naive_bayes = BernoulliNB()\n",
    "\n",
    "# Melatih model Naive Bayes pada data pelatihan\n",
    "naive_bayes.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Prediksi sentimen pada data pelatihan dan data uji\n",
    "y_pred_train_nb = naive_bayes.predict(X_train.toarray())\n",
    "y_pred_test_nb = naive_bayes.predict(X_test.toarray())\n",
    "\n",
    "# Evaluasi akurasi model Naive Bayes\n",
    "accuracy_train_nb = accuracy_score(y_pred_train_nb, y_train)\n",
    "accuracy_test_nb = accuracy_score(y_pred_test_nb, y_test)\n",
    "\n",
    "# Menampilkan akurasi\n",
    "print('Naive Bayes - accuracy_train:', accuracy_train_nb)\n",
    "print('Naive Bayes - accuracy_test:', accuracy_test_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - accuracy_train: 0.9145148356054531\n",
      "Logistic Regression - accuracy_test: 0.8955415374746071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Membuat objek model Logistic Regression\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Melatih model Logistic Regression pada data pelatihan\n",
    "logistic_regression.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Prediksi sentimen pada data pelatihan dan data uji\n",
    "y_pred_train_lr = logistic_regression.predict(X_train.toarray())\n",
    "y_pred_test_lr = logistic_regression.predict(X_test.toarray())\n",
    "\n",
    "# Evaluasi akurasi model Logistic Regression pada data pelatihan\n",
    "accuracy_train_lr = accuracy_score(y_pred_train_lr, y_train)\n",
    "\n",
    "# Evaluasi akurasi model Logistic Regression pada data uji\n",
    "accuracy_test_lr = accuracy_score(y_pred_test_lr, y_test)\n",
    "\n",
    "# Menampilkan akurasi\n",
    "print('Logistic Regression - accuracy_train:', accuracy_train_lr)\n",
    "print('Logistic Regression - accuracy_test:', accuracy_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - accuracy_train: 0.9996792301523657\n",
      "Decision Tree - accuracy_test: 0.7045867636052603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Membuat objek model Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Melatih model Decision Tree pada data pelatihan\n",
    "decision_tree.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Prediksi sentimen pada data pelatihan dan data uji\n",
    "y_pred_train_dt = decision_tree.predict(X_train.toarray())\n",
    "y_pred_test_dt = decision_tree.predict(X_test.toarray())\n",
    "\n",
    "# Evaluasi akurasi model Decision Tree\n",
    "accuracy_train_dt = accuracy_score(y_pred_train_dt, y_train)\n",
    "accuracy_test_dt = accuracy_score(y_pred_test_dt, y_test)\n",
    "\n",
    "# Menampilkan akurasi\n",
    "print('Decision Tree - accuracy_train:', accuracy_train_dt)\n",
    "print('Decision Tree - accuracy_test:', accuracy_test_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy Test\n",
      "0          Naive Bayes       0.753555\n",
      "1  Logistic Regression       0.895542\n",
      "2        Decision Tree       0.704587\n"
     ]
    }
   ],
   "source": [
    "# Membuat DataFrame untuk hasil akurasi\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes', 'Logistic Regression', 'Decision Tree'],\n",
    "    'Accuracy Train': [accuracy_train_nb, accuracy_train_lr, accuracy_train_dt],\n",
    "    'Accuracy Test': [accuracy_test_nb, accuracy_test_lr, accuracy_test_dt]\n",
    "})\n",
    "# Menampilkan hanya kolom \"Accuracy Test\"\n",
    "accuracy_test_only = results_df[['Model', 'Accuracy Test']]\n",
    "print(accuracy_test_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy Test\n",
      "1  Logistic Regression       0.895542\n",
      "0          Naive Bayes       0.753555\n",
      "2        Decision Tree       0.704587\n"
     ]
    }
   ],
   "source": [
    "# Mengurutkan DataFrame berdasarkan kolom \"Accuracy Test\" dari tertinggi ke terendah\n",
    "accuracy_test_sorted = accuracy_test_only.sort_values(by='Accuracy Test', ascending=False)\n",
    "\n",
    "# Menampilkan DataFrame yang telah diurutkan\n",
    "print(accuracy_test_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_casefoldingText</th>\n",
       "      <th>text_slangwords</th>\n",
       "      <th>text_tokenizingText</th>\n",
       "      <th>text_stopword</th>\n",
       "      <th>text_akhir</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya bener2 ngga suka sama yang namanya Kurir ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Saya bener ngga suka sama yang namanya Kurir R...</td>\n",
       "      <td>saya bener ngga suka sama yang namanya kurir r...</td>\n",
       "      <td>saya benar tidak suka sama yang namanya kurir ...</td>\n",
       "      <td>['saya', 'benar', 'tidak', 'suka', 'sama', 'ya...</td>\n",
       "      <td>['suka', 'namanya', 'kurir', 'rekomendasi', 'm...</td>\n",
       "      <td>suka namanya kurir rekomendasi molor kurir upd...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  score  \\\n",
       "0  Saya bener2 ngga suka sama yang namanya Kurir ...      2   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  Saya bener ngga suka sama yang namanya Kurir R...   \n",
       "\n",
       "                                text_casefoldingText  \\\n",
       "0  saya bener ngga suka sama yang namanya kurir r...   \n",
       "\n",
       "                                     text_slangwords  \\\n",
       "0  saya benar tidak suka sama yang namanya kurir ...   \n",
       "\n",
       "                                 text_tokenizingText  \\\n",
       "0  ['saya', 'benar', 'tidak', 'suka', 'sama', 'ya...   \n",
       "\n",
       "                                       text_stopword  \\\n",
       "0  ['suka', 'namanya', 'kurir', 'rekomendasi', 'm...   \n",
       "\n",
       "                                          text_akhir  polarity_score  \\\n",
       "0  suka namanya kurir rekomendasi molor kurir upd...               5   \n",
       "\n",
       "   polarity  text_length  \n",
       "0  positive           30  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimen kalimat baru adalah NEGATIF.\n"
     ]
    }
   ],
   "source": [
    "# Define your preprocessing functions\n",
    "def cleaningText(text):\n",
    "    # Add your text cleaning steps here\n",
    "    cleaned_text = text.lower()\n",
    "    # Add more cleaning steps as needed\n",
    "    return cleaned_text\n",
    "\n",
    "def casefoldingText(text):\n",
    "    # Add your casefolding steps here\n",
    "    casefolded_text = text.lower()\n",
    "    return casefolded_text\n",
    "\n",
    "def fix_slangwords(text):\n",
    "    # Add your slang words fixing steps here\n",
    "    slang_fixed_text = text\n",
    "    return slang_fixed_text\n",
    "\n",
    "def tokenizingText(text):\n",
    "    # Add your tokenizing steps here\n",
    "    tokenized_text = text.split()\n",
    "    return tokenized_text\n",
    "\n",
    "def filteringText(text):\n",
    "    # Add your filtering steps here\n",
    "    filtered_text = [word for word in text if word.isalpha()]\n",
    "    return filtered_text\n",
    "\n",
    "def toSentence(list_words):\n",
    "    # Convert list of words into sentence\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence\n",
    "\n",
    "# Input kalimat baru dari pengguna\n",
    "kalimat_baru = input(\"Masukkan kalimat baru: \")\n",
    "\n",
    "# Melakukan preprocessing pada kalimat baru\n",
    "kalimat_baru_cleaned = cleaningText(kalimat_baru)\n",
    "kalimat_baru_casefolded = casefoldingText(kalimat_baru_cleaned)\n",
    "kalimat_baru_slangfixed = fix_slangwords(kalimat_baru_casefolded)\n",
    "kalimat_baru_tokenized = tokenizingText(kalimat_baru_slangfixed)\n",
    "kalimat_baru_filtered = filteringText(kalimat_baru_tokenized)\n",
    "kalimat_baru_final = toSentence(kalimat_baru_filtered)\n",
    "\n",
    "# Menggunakan objek tfidf yang sudah di-fit dari pelatihan sebelumnya\n",
    "X_kalimat_baru = tfidf.transform([kalimat_baru_final])\n",
    "\n",
    "# Memperoleh prediksi sentimen kalimat baru\n",
    "prediksi_sentimen = logistic_regression.predict(X_kalimat_baru)\n",
    "# Menampilkan hasil prediksi\n",
    "# Menampilkan hasil prediksi\n",
    "if prediksi_sentimen[0] == 'positive':\n",
    "    print(\"Sentimen kalimat baru adalah POSITIF.\")\n",
    "else:\n",
    "    print(\"Sentimen kalimat baru adalah NEGATIF.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, BatchNormalization, Dropout, Activation\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Model Neural Network\n",
    "model_nn = Sequential()\n",
    "\n",
    "# Menambahkan layer input (Dense) dengan BatchNormalization dan Activation\n",
    "model_nn.add(Dense(256, input_dim=X_train.shape[1], kernel_regularizer=regularizers.l2(0.01)))  # L2 regularization\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Activation('relu'))\n",
    "model_nn.add(Dropout(0.4))\n",
    "\n",
    "# Menambahkan layer tersembunyi\n",
    "model_nn.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))  # L2 regularization\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dropout(0.4))\n",
    "\n",
    "model_nn.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))  # L2 regularization\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dropout(0.4))\n",
    "\n",
    "# Layer output untuk 3 kelas (Sentimen: Negatif, Netral, Positif)\n",
    "model_nn.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile model dengan optimizer Adam dan learning rate yang lebih rendah\n",
    "adam_optimizer = Adam(learning_rate=0.0001)  # Menurunkan learning rate\n",
    "model_nn.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fungsi untuk learning rate scheduler\n",
    "def lr_scheduler(epoch):\n",
    "    lr = 0.0001 * (0.1 ** (epoch // 10))  # Menurunkan learning rate setiap 10 epoch\n",
    "    return lr\n",
    "\n",
    "# EarlyStopping untuk menghentikan pelatihan jika model tidak membaik\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Cross-validation untuk menghindari overfitting dan memilih model yang lebih baik\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Melatih model pada fold\n",
    "    print(f\"Training fold {fold}...\")\n",
    "    hist = model_nn.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=1,\n",
    "                        validation_data=(X_val_fold, y_val_fold), callbacks=[early_stop, lr_schedule])\n",
    "\n",
    "    # Evaluasi pada fold\n",
    "    y_pred_train_nn = model_nn.predict(X_train_fold)\n",
    "    y_pred_val_nn = model_nn.predict(X_val_fold)\n",
    "\n",
    "    y_pred_train_nn = y_pred_train_nn.argmax(axis=1)\n",
    "    y_pred_val_nn = y_pred_val_nn.argmax(axis=1)\n",
    "\n",
    "    accuracy_train_nn = accuracy_score(y_train_fold, y_pred_train_nn)\n",
    "    accuracy_val_nn = accuracy_score(y_val_fold, y_pred_val_nn)\n",
    "\n",
    "    print(f\"Fold {fold} - Train Accuracy: {accuracy_train_nn}, Validation Accuracy: {accuracy_val_nn}\")\n",
    "    fold += 1\n",
    "\n",
    "# Evaluasi akhir pada data uji\n",
    "y_pred_test_nn = model_nn.predict(X_test)\n",
    "y_pred_test_nn = y_pred_test_nn.argmax(axis=1)\n",
    "\n",
    "accuracy_test_nn = accuracy_score(y_test, y_pred_test_nn)\n",
    "print('Final Model Accuracy on Test Data:', accuracy_test_nn)\n",
    "\n",
    "# Plotting loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
